Got it. Two different problems are getting mixed together:

Your code isn’t “QuantConnect-algorithm-shaped,” so QC can’t import it.

Even when it is QC-shaped, Replit/QC will still hide errors unless you force a strict “compile + unit-test” pipeline.

Below I’ll do Option 2 (GSA Research Hardening) and Option 3 (QC bridge file), plus the exact fixes for the “Unable to import … ensure one class inherits QCAlgorithm” error.

Why you’re getting “Unable to import … ensure one class inherits QCAlgorithm”

That error means QC tried to load main.py (compiled to main.pyc) and did not find a valid algorithm class inheriting QCAlgorithm, or import failed before it could load due to a crash at import-time.

Common causes:

Your file is a standalone script (like the GSA with yfinance, pandas, if __name__ == "__main__": run_gsa_demo()), not a QC algorithm.

You have top-level code that runs on import (QC imports your module; it does not want a script that executes immediately).

You use libraries QC doesn’t support (yfinance, most of pandas usage, file system caching, etc.).

So: GSA can exist as “research code”, but QC needs a bridge that uses AlgorithmImports, History(), indicators, and a single class X(QCAlgorithm).

Option 2 — GSA Research Hardening (what to fix next, rigorously)

Your SWOT already nails the big technical liabilities:

A) Remove “arbitrary constants” by turning them into estimated parameters

GSA has coefficient/weight choices and kernel decays called out as arbitrary. 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE

LCC has multiple “hardcoded constants” + “arbitrary coefficients” called out as critical. 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE

 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE

Hardening move: make a params object and fit it.

Fit targets can be: next-day/next-week return, drawdown risk, or regime classification accuracy.

Use walk-forward + rolling windows.

Penalize complexity (so it doesn’t overfit).

B) Fix the “regime state bleed between tickers”

This is a huge one: the SWOT points out your backtest uses one shared RegimeClassifier so PD/constraint history contaminates other tickers. 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE

Hardening move: one classifier per ticker:

self.regime_classifier: Dict[str, RegimeClassifier] = {t: RegimeClassifier() for t in tickers}

C) Make performance claims scientifically defensible

Your SWOT doc lists strong claims that are currently “in-sample/unverified.” 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE

 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE


Hardening move: you need:

Out-of-sample windows (e.g., train 2010–2018, test 2019–2021; roll forward).

Slippage + fees (QC has models; research harness should simulate).

Survivorship bias control (avoid “today’s winners only” universes).

Compare to baselines: SPY buy/hold, equal-weight basket, simple momentum, simple mean-reversion.

D) Address the “0.85 causation threshold” as a hypothesis, not a truth

Your SWOT states the 0.92²≈0.85 threshold and “correlation becomes causation” claim. 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE


Hardening move: treat it as:

a gating heuristic you can optimize (or reject),

and validate whether any threshold improves forward prediction.

E) “LCC’s acquisition of probability” → make it explicit and testable

Right now, the doc itself flags circularity and lack of ground truth for text→EEG and the core coupling formulas. 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE


Hardening move: define LCC probability acquisition as a measurable quantity:

Example: “Probability acquisition = reduction in predictive entropy after integrating stream X.”

Then test: does adding LCC streams reduce forecast error on held-out data?

Option 3 — QC Bridge File (turn GSA into QC-runnable shape)
The key architecture

You will have two layers:

gsa_core.py (research-friendly math, no yfinance, no pandas, no file I/O)

main.py (QuantConnect algorithm) that:

pulls price history via self.History()

updates rolling windows

calls gsa_core functions

places orders

This clean split is what stops “Replit blindness,” because you can unit-test gsa_core.py locally without QC.

The bridge code you can copy-paste into QuantConnect
File 1: gsa_core.py (QC-safe core, pure numpy + builtins)
# gsa_core.py
import numpy as np

SACRED_MIN, SACRED_MAX = -0.666, 0.333

class MarketRegime:
    EXPANSION = "expansion"
    COMPRESSION = "compression"
    FRACTURE = "fracture"
    RESET = "reset"

def safe_std(x: np.ndarray, floor: float = 1e-6) -> float:
    s = float(np.std(x)) if len(x) > 1 else 0.0
    return max(s, floor)

def calculate_amplitude(returns: np.ndarray) -> float:
    if len(returns) < 2:
        return 0.0
    cur = abs(float(returns[-1]))
    vol = safe_std(returns, 0.01)
    return float(np.clip(cur / vol, 0.0, 10.0))

def calculate_memory_kernel(returns: np.ndarray, decay_pos: float = 0.1, decay_neg: float = 0.05) -> float:
    if len(returns) < 3:
        return 0.5
    # most-recent should weigh more: reverse so i=0 is most recent
    r = returns[::-1]
    pos = r[r > 0]
    neg = r[r < 0]
    k_pos = sum(abs(float(v)) * np.exp(-decay_pos * i) for i, v in enumerate(pos))
    k_neg = sum(abs(float(v)) * np.exp(-decay_neg * i) for i, v in enumerate(neg))
    tot = k_pos + k_neg
    return float(np.clip(k_neg / tot, 0.0, 1.0)) if tot > 0 else 0.5

def calculate_constraint(prices: np.ndarray, returns: np.ndarray, lookback_short: int = 7, lookback_long: int = 30) -> float:
    if len(prices) < 5:
        return 0.0
    peak = float(np.max(prices))
    last = float(prices[-1])
    dd = (peak - last) / peak if peak > 0 else 0.0

    r_short = returns[-lookback_short:] if len(returns) >= lookback_short else returns
    r_long = returns[-lookback_long:] if len(returns) >= lookback_long else returns
    vol_short = safe_std(r_short, 0.01)
    vol_long = safe_std(r_long, 0.01)

    vol_constraint = 1.0 - min(vol_short / max(vol_long, 0.01), 1.0)
    return float(np.clip(0.6 * dd + 0.4 * vol_constraint, 0.0, 1.0))

def valence_weight(return_pct: float) -> float:
    # keep your PD mapping but make it easy to calibrate later
    if return_pct > 5.0: return 1.5
    if return_pct > SACRED_MAX: return 1.0
    if return_pct > SACRED_MIN: return 1.0
    if return_pct > -5.0: return 2.0
    return 6.0

def compute_xi(prices: np.ndarray, returns_pct: np.ndarray,
               lb_short: int = 7, lb_long: int = 30) -> dict:
    if len(returns_pct) < max(5, lb_short):
        return dict(A=0.0, kappa=0.5, C=0.0, xi_unsigned=0.0, xi_signed=0.0, pd=0.0)

    A = calculate_amplitude(returns_pct[-lb_short:])
    kappa = calculate_memory_kernel(returns_pct[-lb_long:])
    C = calculate_constraint(prices[-lb_long:], returns_pct[-lb_long:], lb_short, lb_long)

    xi_unsigned = A * kappa * C
    r = float(returns_pct[-1])
    sgn = 1.0 if r >= 0 else -1.0
    xi_signed = sgn * xi_unsigned * valence_weight(r)

    pd = float(np.clip(np.sign(xi_signed) * np.log1p(abs(xi_signed)), -3.0, 2.0))
    return dict(A=A, kappa=kappa, C=C, xi_unsigned=xi_unsigned, xi_signed=xi_signed, pd=pd)

def classify_regime(pd_hist: list, c_hist: list, returns_pct: np.ndarray) -> tuple:
    # lightweight regime logic you can later replace with your full classifier
    if len(returns_pct) < 30 or len(pd_hist) < 10 or len(c_hist) < 10:
        return (MarketRegime.EXPANSION, 0.4)

    recent_c = float(np.mean(c_hist[-5:]))
    older_c = float(np.mean(c_hist[-10:-5]))
    c_rate = recent_c - older_c

    recent_vol = safe_std(returns_pct[-10:], 0.01)
    long_vol = safe_std(returns_pct[-30:], 0.01)
    vol_ratio = recent_vol / max(long_vol, 0.01)

    pd_now = float(pd_hist[-1])

    if c_rate > 0.1 and vol_ratio > 1.5 and pd_now < -1.0:
        return (MarketRegime.FRACTURE, min(0.9, 0.5 + abs(c_rate) + abs(pd_now)/3.0))
    if c_rate > 0.05 and vol_ratio < 0.7:
        return (MarketRegime.COMPRESSION, min(0.8, 0.5 + c_rate*2.0 + (1.0 - vol_ratio)))
    if c_rate < -0.05 and vol_ratio > 1.0:
        return (MarketRegime.RESET, min(0.8, 0.5 + abs(c_rate) + (vol_ratio - 1.0)*0.5))
    return (MarketRegime.EXPANSION, max(0.4, 0.7 - abs(c_rate)*2.0))

File 2: main.py (the QC algorithm wrapper)
# main.py
from AlgorithmImports import *
import numpy as np
import gsa_core as core

class TI_GSA_QC_Bridge(QCAlgorithm):
    def Initialize(self):
        self.SetStartDate(2020, 1, 1)
        self.SetEndDate(2024, 12, 1)
        self.SetCash(100000)

        tickers = ["SPY", "QQQ", "AAPL", "MSFT", "GOOGL", "NVDA", "TSLA", "META", "AMZN"]
        self.symbols = [self.AddEquity(t, Resolution.Daily).Symbol for t in tickers]

        self.lb_short = 7
        self.lb_long = 30
        self.window = 80  # enough to compute everything safely

        # per-symbol state (prevents the “ticker bleed” issue your SWOT flagged) :contentReference[oaicite:8]{index=8}
        self.state = {}
        for s in self.symbols:
            self.state[s] = {
                "prices": RollingWindow[float](self.window),
                "returns": RollingWindow[float](self.window),
                "pd_hist": [],
                "c_hist": []
            }

        self.max_pos = 0.12
        self.top_k = 4

        self.SetWarmUp(self.window, Resolution.Daily)
        self.Schedule.On(self.DateRules.EveryDay("SPY"),
                         self.TimeRules.AfterMarketOpen("SPY", 30),
                         self.Rebalance)

    def OnData(self, data: Slice):
        # update rolling windows
        for s in self.symbols:
            sec = self.Securities[s]
            if not sec.HasData or sec.Price <= 0:
                continue

            st = self.state[s]
            prev_price = st["prices"][0] if st["prices"].Count > 0 else None

            st["prices"].Add(float(sec.Price))
            if prev_price is not None and prev_price > 0:
                r = (float(sec.Price) / float(prev_price) - 1.0) * 100.0
                st["returns"].Add(float(r))
            else:
                st["returns"].Add(0.0)

    def Rebalance(self):
        if self.IsWarmingUp:
            return

        signals = []
        for s in self.symbols:
            st = self.state[s]
            if st["prices"].Count < self.lb_long or st["returns"].Count < self.lb_long:
                continue

            prices = np.array([st["prices"][i] for i in range(st["prices"].Count)][::-1], dtype=float)
            rets   = np.array([st["returns"][i] for i in range(st["returns"].Count)][::-1], dtype=float)

            xi = core.compute_xi(prices, rets, self.lb_short, self.lb_long)
            st["pd_hist"].append(xi["pd"])
            st["c_hist"].append(xi["C"])
            st["pd_hist"] = st["pd_hist"][-120:]
            st["c_hist"]  = st["c_hist"][-120:]

            regime, reg_conf = core.classify_regime(st["pd_hist"], st["c_hist"], rets)

            # simple scoring: PD as “signal strength”, fracture = hard risk-off
            score = xi["pd"]

            if regime == core.MarketRegime.FRACTURE:
                score = -10  # force to bottom

            signals.append((s, score, regime, reg_conf, xi))

        if not signals:
            return

        # rank by score
        signals.sort(key=lambda x: x[1], reverse=True)
        buys = [x for x in signals if x[1] > 0.3][:self.top_k]

        # liquidate losers / non-selected holdings
        selected = set([b[0] for b in buys])
        for kvp in self.Portfolio:
            sym = kvp.Key
            if kvp.Value.Invested and sym not in selected:
                self.Liquidate(sym, "Not in top set")

        # allocate equally across selected, scaled by regime confidence
        if len(buys) == 0:
            return

        base_w = min(self.max_pos, 1.0 / len(buys))
        for (s, score, regime, reg_conf, xi) in buys:
            w = base_w * min(1.0, max(0.25, reg_conf))
            self.SetHoldings(s, w)

        self.Log(f"Rebalance: selected={[self.SymbolCache.GetTicker(s) for s in selected]}")

Why this bridge works

QC sees exactly one class ... (QCAlgorithm) in main.py → fixes your import error.

No yfinance, no pandas, no caching to disk.

No top-level execution (if __name__ == "__main__":) that would crash QC imports.

Fixes the “regime classifier bleed across tickers” by keeping state per symbol (this was flagged as a major weakness). 

SWOT_ANALYSIS_GSA_LCC_CRITIQUE

Should you upload/copy all three options?

You don’t need to upload everything every time.

What you do need is:

QC project: main.py + optionally gsa_core.py (and any other modules QC supports)

Replit research project: the heavier GSA (pandas/yfinance) + your calibration + plotting

So: copy/upload only the files relevant to that environment.

If you want the cleanest workflow:

Keep one “source of truth” for math (gsa_core.py)

QC imports it

Replit research imports it

Then you tune params in research and copy only param values back into QC